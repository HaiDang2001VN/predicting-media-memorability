{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "video-mem",
      "language": "python",
      "name": "video-mem"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MediaEval20 - UCB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgsSrq5AVT1r"
      },
      "source": [
        "# Training workflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AgkIHQZVT10"
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhbycpnhaRaV",
        "outputId": "273dadd4-8ac5-4bda-c7a7-7689745767ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbjjPcz8h4nW",
        "outputId": "a00e589d-f609-45ac-b9b4-08dff063c2a0"
      },
      "source": [
        "%pip install -U fer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fer in /usr/local/lib/python3.7/dist-packages (21.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fer) (2.23.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fer) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fer) (4.62.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n",
            "Requirement already satisfied: mtcnn>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from fer) (0.1.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn>=0.1.1->fer) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fer) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fer) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYWW9avoWFjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3adc836d-516f-40a7-a9e7-74ec54172bd4"
      },
      "source": [
        "%cd /content\n",
        "%rm -rf ucb\n",
        "!git clone https://github.com/HaiDang2001VN/predicting-media-memorability.git ucb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ucb'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 180 (delta 94), reused 137 (delta 51), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 1.11 MiB | 9.60 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x70BiKP1ZXoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a1b0e9-d39d-4b95-9cb1-17e4259119b7"
      },
      "source": [
        "%cd /content/ucb\n",
        "%rm -rf training_set\n",
        "%mkdir training_set\n",
        "!find '/content/drive/MyDrive/HCMUS/AI/MedEval21/Memorability/2021-Predicting-Media-Memorability-Task/TRECVid Data/training_set' \\( -name \"train_*.csv\" \\) -exec cp {} training_set \\;\n",
        "%ls -sla training_set"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "total 2948\n",
            "   4 drwxr-xr-x 2 root root    4096 Oct 17 13:06 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "   4 drwxr-xr-x 5 root root    4096 Oct 17 13:06 \u001b[01;34m..\u001b[0m/\n",
            " 592 -r-------- 1 root root  602173 Oct 17 13:06 train_long_term_annotations.csv\n",
            "  96 -r-------- 1 root root   94598 Oct 17 13:06 train_scores.csv\n",
            "1736 -r-------- 1 root root 1775597 Oct 17 13:06 train_short_term_annotations.csv\n",
            " 448 -r-------- 1 root root  458640 Oct 17 13:06 train_text_descriptions.csv\n",
            "  68 -r-------- 1 root root   66915 Oct 17 13:06 train_video_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682RGXVjbgLX",
        "outputId": "f685d8d9-ac15-478d-c084-2ce6b04d30f0"
      },
      "source": [
        "%cd /content/ucb\n",
        "%rm -rf testing_set\n",
        "%mkdir testing_set\n",
        "!find '/content/drive/MyDrive/HCMUS/AI/MedEval21/Memorability/2021-Predicting-Media-Memorability-Task/TRECVid Data/testing_set' \\( -name \"test_*.csv\" \\) -exec cp {} testing_set \\;\n",
        "%ls -sla testing_set"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "total 2360\n",
            "   4 drwxr-xr-x 2 root root    4096 Oct 17 13:06 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "   4 drwxr-xr-x 6 root root    4096 Oct 17 13:06 \u001b[01;34m..\u001b[0m/\n",
            " 696 -r-------- 1 root root  709011 Oct 17 13:06 test_long_term_annotations.csv\n",
            "1236 -r-------- 1 root root 1261867 Oct 17 13:06 test_short_term_annotations.csv\n",
            " 364 -r-------- 1 root root  371542 Oct 17 13:06 test_text_descriptions.csv\n",
            "  56 -r-------- 1 root root   56892 Oct 17 13:06 test_video_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1ICO_ebbv8K",
        "outputId": "4ea0426c-198c-4dbf-af1d-57321fbc38e1"
      },
      "source": [
        "!python setup_train.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening training_set/train_video_urls.csv...\n",
            "Downloading videos: 100% 588/588 [01:03<00:00,  9.32it/s]\n",
            "Extracting audio: 100% 588/588 [00:53<00:00, 10.98it/s]\n",
            "Extracting 8 frames per video:  47% 275/588 [04:33<05:31,  1.06s/it]\u001b[0;36m[h264 @ 0x5632af048880] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632af047680] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632af047680] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  54% 318/588 [05:19<05:56,  1.32s/it]\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad575a80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad575a80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad575a80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad575a80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad575a80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad575a80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "Extracting 8 frames per video:  79% 463/588 [07:42<02:53,  1.39s/it]\u001b[0;36m[h264 @ 0x5632af049180] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573200] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5632ad573200] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video: 100% 588/588 [09:50<00:00,  1.00s/it]\n",
            "Finished setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2yEY246cHiZ",
        "outputId": "d6cb62b5-96ac-4536-ac9d-20d38bccaa1c"
      },
      "source": [
        "!python setup_test.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening testing_set/test_video_urls.csv...\n",
            "Downloading videos: 100% 500/500 [00:53<00:00,  9.31it/s]\n",
            "Extracting audio: 100% 500/500 [00:43<00:00, 11.59it/s]\n",
            "Extracting 8 frames per video:   3% 13/500 [00:11<06:44,  1.20it/s]\u001b[0;36m[h264 @ 0x5629ea507180] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea505200] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea505200] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  15% 77/500 [01:16<06:42,  1.05it/s]\u001b[0;36m[h264 @ 0x5629ea506d00] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea506880] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea506880] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  50% 252/500 [04:14<03:28,  1.19it/s]\u001b[0;36m[h264 @ 0x5629ea506d00] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea506880] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea506880] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  70% 350/500 [05:51<02:25,  1.03it/s]\u001b[0;36m[h264 @ 0x5629ea505f80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea507600] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea507600] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  92% 461/500 [07:41<00:40,  1.05s/it]\u001b[0;36m[h264 @ 0x5629ea505f80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea505200] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x5629ea505200] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video: 100% 500/500 [08:26<00:00,  1.01s/it]\n",
            "Finished setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldb5U0G6tOQb"
      },
      "source": [
        "# %cd /content/ucb/training_set\n",
        "# %rm -rf Features\n",
        "# %mkdir Features\n",
        "# %cp '/content/drive/MyDrive/HCMUS/AI/MedEval21/Memorability/2021-Predicting-Media-Memorability-Task/TRECVid Data/training_set/Features/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LalNeqz2pCZt",
        "outputId": "5ee67050-f1ee-41b6-8447-462076ef950b"
      },
      "source": [
        "%cd /content/ucb\n",
        "%rm -rf data\n",
        "%mkdir data\n",
        "%mkdir data/glove.6B\n",
        "!unzip /content/drive/MyDrive/HCMUS/AI/MedEval21/glove.6B.300d.txt -d data/glove.6B\n",
        "%ls -sla data/glove.6B"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Archive:  /content/drive/MyDrive/HCMUS/AI/MedEval21/glove.6B.300d.txt.zip\n",
            "  inflating: data/glove.6B/glove.6B.300d.txt  \n",
            "total 1013648\n",
            "      4 drwxr-xr-x 2 root root       4096 Oct 17 13:28 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "      4 drwxr-xr-x 3 root root       4096 Oct 17 13:28 \u001b[01;34m..\u001b[0m/\n",
            "1013640 -rw-r--r-- 1 root root 1037962819 Sep 22  2019 glove.6B.300d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvcbirUEnvkv",
        "outputId": "9744ca4a-6d64-46ff-cfdb-ee71b6f5a683"
      },
      "source": [
        "%cd /content/ucb\n",
        "%mkdir training_set/Features\n",
        "%mkdir training_set/Features/GloVe\n",
        "%mkdir testing_set/Features\n",
        "%mkdir testing_set/Features/GloVe\n",
        "!python extract_features.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Extract all features? (y/n) Otherwise extract on per-feature basis.n\n",
            "Extract emotion features? (y/n)n\n",
            "Extract text (GLoVe) features? (y/n)y\n",
            "\tFound 3974 captions for 1088 videos\n",
            "\tAvg num of captions per video: 3.6525735294117645\n",
            "\tMax num of captions per video: 6\n",
            "\tMin num of captions per video: 2\n",
            "Max sequence length: 86\n",
            "Min sequence length: 2\n",
            "Avg sequence length: 17.81857070961248\n",
            "Fitting tokenizer...\n",
            "Extracting GLoVe features from training_set/train_text_descriptions.csv...\n",
            "2021-10-17 13:29:25.984157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.027793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.028657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.030195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.030970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.031670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.529247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.530512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.531489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-17 13:29:26.532451: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-10-17 13:29:26.532607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10818 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "2021-10-17 13:29:26.595996: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-10-17 13:29:26.744836: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 225388800 exceeds 10% of free system memory.\n",
            "100% 2184/2184 [00:36<00:00, 59.23it/s]\n",
            "Extracting GLoVe features from testing_set/test_text_descriptions.csv...\n",
            "2021-10-17 13:30:22.581136: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 184728000 exceeds 10% of free system memory.\n",
            "100% 1790/1790 [00:30<00:00, 59.23it/s]\n",
            "Saving tokenizer at features//caption_tokenizer.pickle\n",
            "Finished GLoVe feature extraction.\n",
            "\n",
            "Extract image (ResNet152) features? (y/n)n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ni1n5l3VT15"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "import features.config as fconf"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfoIgxf_VT18"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzB82VygVT19"
      },
      "source": [
        "PREDICTIONS_DIR = \"predictions\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0jKz4zkVT1-"
      },
      "source": [
        "SAVE_MODEL = True\n",
        "IS_SHORT_TERM = True\n",
        "\n",
        "USE_DEV_SET = False\n",
        "USE_TRAIN_SET = True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLWvk5umVT2A"
      },
      "source": [
        "RANDOM_SEED = 42"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f41oGQocVT2B"
      },
      "source": [
        "target = \"m_75\" if IS_SHORT_TERM else \"part_2_scores\"\n",
        "feature = \"glove\"\n",
        "model_type = \"gru\"\n",
        "aggregate_with = np.median"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Efes_kVT2C"
      },
      "source": [
        "model_name = f\"{feature}_{model_type}\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJoXdSvRVT2E"
      },
      "source": [
        "model_parameters = {\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"use_dev_set\": USE_DEV_SET,\n",
        "}\n",
        "\n",
        "if model_type == \"gru\":\n",
        "    model_parameters[\"hidden_dim\"] = 64\n",
        "    model_parameters[\"learning_rate\"] = 1e-3\n",
        "    model_parameters[\"num_epochs\"] = 150\n",
        "    model_parameters[\"batch_size\"] = 64\n",
        "    model_parameters[\"gru_units\"] = 64\n",
        "    model_parameters[\"gru_dropout\"] = 0.8"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwll8cjrVT2N"
      },
      "source": [
        "NOTES = \"\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNQuacdRVT2P"
      },
      "source": [
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxy1ZO5QVT2P"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Extracted features, scores, metadata, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-LPx_W0VT2R"
      },
      "source": [
        "testing_set_data = pd.read_csv(\"testing_set/test_video_urls.csv\").set_index(\"video_id\")\n",
        "\n",
        "if USE_TRAIN_SET:\n",
        "    training_set_data = pd.read_csv(\"training_set/train_video_urls.csv\").set_index(\"video_id\")\n",
        "\n",
        "if USE_DEV_SET:\n",
        "    development_set_data = pd.read_csv(\"development_set/dev_video_urls.csv\").set_index(\"video_id\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLLbqhvrVT2R"
      },
      "source": [
        "from features.video import load_C3D_features\n",
        "from features.image import load_ResNet152_features, load_LBP_features, load_HOG_features\n",
        "from features.audio import load_VGGish_features\n",
        "from features.text import load_GloVe_features\n",
        "from features.emotion import load_Emotion_features, extract_emotions\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJk0RQ8lVT2T"
      },
      "source": [
        "def add_features_to_df(dfs, set_names, label, feature_dir, load_func):\n",
        "    for df, set_name in zip(dfs, set_names):\n",
        "        df[label] = load_func(df.index, fconf.set_dataset(set_name, feature_dir))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NcFNgmcVT2T"
      },
      "source": [
        "dfs = [testing_set_data]\n",
        "set_names = [\"testing_set\"]\n",
        "\n",
        "if USE_TRAIN_SET:\n",
        "    dfs.append(training_set_data)\n",
        "    set_names.append(\"training_set\")\n",
        "\n",
        "if USE_DEV_SET:\n",
        "    dfs.append(development_set_data)\n",
        "    set_names.append(\"development_set\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoZIqjMYVT2U"
      },
      "source": [
        "# Emotion\n",
        "if feature == \"emotion\":\n",
        "    add_features_to_df(dfs, set_names, \"emotion\",\n",
        "                      fconf.EMOTION_FEATURE_DIR, load_Emotion_features)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7yBbEURVT2U"
      },
      "source": [
        "# LBP\n",
        "if feature == \"lbp\":\n",
        "    add_features_to_df(dfs, set_names, \"lbp\",\n",
        "                      fconf.LBP_FEATURE_DIR, load_LBP_features)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2TDApJVT2V"
      },
      "source": [
        "# HOG\n",
        "if feature == \"hog\":\n",
        "    add_features_to_df(dfs, set_names, \"hog\",\n",
        "                      fconf.HOG_FEATURE_DIR, load_HOG_features)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzUTraoVVT2W"
      },
      "source": [
        "# ResNet152\n",
        "if feature == \"resnet152\":\n",
        "    add_features_to_df(dfs, set_names, \"resnet152\",\n",
        "                      fconf.RESNET152_FEATURE_DIR, load_ResNet152_features)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sutpUOJwVT2X"
      },
      "source": [
        "# C3D\n",
        "if feature == \"c3d\":\n",
        "    add_features_to_df(dfs, set_names, \"c3d\",\n",
        "                      fconf.C3D_FEATURE_DIR, load_C3D_features)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoLdQ3Y4VT2X"
      },
      "source": [
        "# VGGish\n",
        "if feature == \"vggish\":\n",
        "    add_features_to_df(dfs, set_names, \"vggish\",\n",
        "                      fconf.VGGISH_FEATURE_DIR, load_VGGish_features)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfOQDK2VT2X"
      },
      "source": [
        "# GLoVE\n",
        "if feature == \"glove\":\n",
        "    add_features_to_df(dfs, set_names, \"glove\",\n",
        "                      fconf.GLOVE_FEATURE_DIR, load_GloVe_features)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN4wg9pDVT2Y"
      },
      "source": [
        "test_data = testing_set_data\n",
        "\n",
        "if USE_DEV_SET and USE_TRAIN_SET:\n",
        "    train_data = pd.concat([training_set_data, development_set_data])\n",
        "elif USE_DEV_SET and not USE_TRAIN_SET:\n",
        "    train_data = development_set_data\n",
        "elif USE_TRAIN_SET and not USE_DEV_SET:\n",
        "    train_data = training_set_data\n",
        "else:\n",
        "    raise ValueError(\"train_data is empty\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yXl1lBvVT2Y"
      },
      "source": [
        "## Target Prep\n",
        "\n",
        "Khosla points out that the memorability score used in Isola's paper did not take into account the memory retention duration.\n",
        "Cohendet utilized the same idea as Khosla, which involved a decay rate\n",
        "\n",
        "$$\\alpha \\leftarrow \n",
        "\\frac{\\sum^N_{i=1}\\frac{1}{n^{(i)}} \\sum^{n^{(i)}}_{j=1} \\log(\\frac{t^{(i)}_j}{T})[x^{(i)}_j - m^{(i)}_T] }\n",
        "{\\sum^N_{i=1}\\frac{1}{n^{(i)}} \\sum^{n^{(i)}}_{j=1}[ \\log(\\frac{t^{(i)}_j}{T})]^2}\n",
        "$$\n",
        "\n",
        "to calculate memorability \n",
        "$$\n",
        "m_T^{(i)} \\leftarrow\n",
        "\\frac{1}{n^{(i)}} \\sum^{n^{(i)}}_{j=1}[x^{(i)}_j - \\alpha \\log(\\frac{t_j^{(i)}}{T})]\n",
        "$$\n",
        "\n",
        "where we have $n^{(i)}$ observations for image $i$ given by $x^{(i)} \\in {0,1}$ and $t^{(i)}_j$ where $x_j=1$  implies that the image repeat was correctly detected when it shown after time $t_j$\n",
        "\n",
        "IDEA: potentially explore calculating $\\alpha$ per user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woV8sDXFVT2Z"
      },
      "source": [
        "from target_augmentation import add_position_delta, calculate_alpha_and_memorability"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT5iAGPNVT2Z"
      },
      "source": [
        "if USE_DEV_SET and USE_TRAIN_SET:\n",
        "    annotations = add_position_delta(pd.concat([\n",
        "        pd.read_csv(\"training_set/short_term_annotations_v2.csv\"),\n",
        "        pd.read_csv(\"development_set/dev_short_term_annotations.csv\")\n",
        "    ]))\n",
        "elif USE_TRAIN_SET and not USE_DEV_SET:\n",
        "    annotations = add_position_delta(pd.read_csv(\"training_set/train_short_term_annotations.csv\"))\n",
        "elif USE_DEV_SET and not USE_TRAIN_SET:\n",
        "    annotations = add_position_delta(pd.read_csv(\"development_set/dev_short_term_annotations.csv\"))\n",
        "else:\n",
        "    raise ValueError(\"annotations is empty\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fK6Wy9KlsUB",
        "outputId": "d4d1c953-1538-4472-fe01-3442ecd0fc55"
      },
      "source": [
        "print(\"Average t:\", np.mean(annotations[\"t\"]))\n",
        "\n",
        "# We use approximately the average_t to calculate T as the memorability in question\n",
        "big_t = int(np.around(np.mean(annotations[\"t\"])))\n",
        "label = f\"m_{big_t}\"\n",
        "print(f\"Calculating adjusted value for {label}\")\n",
        "alpha, adjusted_score = calculate_alpha_and_memorability(annotations, T = big_t)\n",
        "train_data[label] = adjusted_score\n",
        "test_data[label] = np.nan\n",
        "print(f\"Alpha: {alpha}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average t: 74.96191840735993\n",
            "Calculating adjusted value for m_75\n",
            "Alpha: -0.026433626378523905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LUote5imBH-",
        "outputId": "b254a52d-9830-4bbd-970b-335384983861"
      },
      "source": [
        "train_scores = pd.read_csv('training_set/train_scores.csv')\n",
        "train_scores.info()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 588 entries, 0 to 587\n",
            "Data columns (total 8 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   video_id                      588 non-null    int64  \n",
            " 1   video_url                     588 non-null    object \n",
            " 2   annotations_short_term        588 non-null    int64  \n",
            " 3   annotations_long_term         588 non-null    int64  \n",
            " 4   scores_raw_short_term         588 non-null    float64\n",
            " 5   scores_raw_long_term          588 non-null    float64\n",
            " 6   scores_normalized_short_term  588 non-null    float64\n",
            " 7   decay_alpha                   588 non-null    float64\n",
            "dtypes: float64(4), int64(3), object(1)\n",
            "memory usage: 36.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "iBPqAq9jVT2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "2d412428-1b1d-4a7b-c930-2d14cc2ceb54"
      },
      "source": [
        "train_data = train_data.merge(train_scores[['video_id', 'scores_raw_short_term']], on='video_id')\n",
        "target_diff = train_data[\"scores_raw_short_term\"] - train_data[label]\n",
        "print(\"Avg diff:\", np.mean(target_diff))\n",
        "print(\"Max diff:\", np.max(target_diff))\n",
        "print(\"Min diff:\", np.min(target_diff))\n",
        "plt.scatter(train_data[\"scores_raw_short_term\"], train_data[label])\n",
        "plt.xlabel(\"Original memorability score\")\n",
        "plt.ylabel(f\"Adjusted memorability score ({label})\")\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg diff: 0.00038440999890361136\n",
            "Max diff: 0.007422429973521383\n",
            "Min diff: -0.006598279844217569\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_eo8ho-VT2a"
      },
      "source": [
        "## Data Prep\n",
        "\n",
        "Building datasets\n",
        "\n",
        "potentially weighting samples based on annotations?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hohUg9oHVT2b"
      },
      "source": [
        "from train import split_training, build_matrixes"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKoy3vrXVT2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00214f68-818c-41e2-e4c4-0004f11be7ec"
      },
      "source": [
        "training_data, validation_data = split_training(train_data)\n",
        "print(\"training:\",len(training_data))\n",
        "print(\"validation:\", len(validation_data))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training: 470\n",
            "validation: 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tHgYo_MVT2c"
      },
      "source": [
        "#### Pick Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA2M2fm2VT2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fb1443-b495-4a54-8491-abca47e430e4"
      },
      "source": [
        "features_train, targets_train, video_ids_train = build_matrixes(training_data, target_name = target, feature_name = feature)\n",
        "features_valid, targets_valid, video_ids_valid = build_matrixes(validation_data, target_name = target, feature_name = feature)\n",
        "features_test, targets_test, video_ids_test = build_matrixes(test_data, target_name = target, feature_name = feature, is_test = True)\n",
        "\n",
        "\n",
        "print(\"num videos in training set:\", len(training_data))\n",
        "print(\"num videos in validation set:\", len(validation_data))\n",
        "print(\"num videos in test set:\", len(test_data))\n",
        "print(\"features_train shape:\", features_train.shape)\n",
        "print(\"targets_train shape:\", targets_train.shape)\n",
        "print(\"features_valid shape:\", features_valid.shape)\n",
        "print(\"targets_valid shape:\", targets_valid.shape)\n",
        "total_features = len(features_train) + len(features_valid)\n",
        "unique, count = np.unique(np.concatenate([video_ids_valid, video_ids_train]), return_counts=True)\n",
        "print(\"Total features:\", total_features)\n",
        "print(\"Total videos:\", len(unique))\n",
        "print(\"Avg features per video:\", total_features / len(unique))\n",
        "print(\"Min features per video:\", min(count))\n",
        "print(\"Max features per video:\", max(count))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num videos in training set: 470\n",
            "num videos in validation set: 118\n",
            "num videos in test set: 500\n",
            "features_train shape: (1758, 86, 300)\n",
            "targets_train shape: (1758, 1)\n",
            "features_valid shape: (426, 86, 300)\n",
            "targets_valid shape: (426, 1)\n",
            "Total features: 2184\n",
            "Total videos: 588\n",
            "Avg features per video: 3.7142857142857144\n",
            "Min features per video: 2\n",
            "Max features per video: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyNQdNwmVT2g"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "z9sG6MZyVT2g"
      },
      "source": [
        "from train import train_model       "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZUjx7dnUVT2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b618840-c5a4-4e61-c472-1c595ffdca9a"
      },
      "source": [
        "model = train_model(model_type, features_train, targets_train, features_valid, targets_valid, model_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input dimensions: (86, 300)\n",
            "hidden dimension: 64\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QboEapcKVT2h"
      },
      "source": [
        "## Test\n",
        "\n",
        "Spearman's rank correlation, ROC curves, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2ciKpKVT2h"
      },
      "source": [
        "from train import get_predictions\n",
        "\n",
        "predictions, actuals, _ = get_predictions(\n",
        "    model_type, model, features_valid, targets_valid, video_ids_valid, aggregate_with=aggregate_with\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "doN3okHpVT2i"
      },
      "source": [
        "spearman_rank, _ = stats.spearmanr(actuals, predictions)\n",
        "print(\"SPEARMAN RANK:\",spearman_rank)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(8,8))\n",
        "min_mem = min(np.min(actuals), np.min(predictions))\n",
        "max_mem = max(np.max(actuals), np.max(predictions))\n",
        "plt.scatter(actuals, predictions, label = f\"Spearman rank correlation = {spearman_rank}\")\n",
        "# plt.plot([min_mem, max_mem], [min_mem, max_mem], label=\"1 to 1\")\n",
        "plt.title(f\"actual {target} vs predicted {target}\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"predictions\")\n",
        "plt.xlabel(\"actual\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zaUtVaJVT2j"
      },
      "source": [
        "# Saving Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trT0ONvIVT2k"
      },
      "source": [
        "pred_train, actual_train, vid_train = get_predictions(model_type, model, features_train, targets_train, video_ids_train, aggregate_with=aggregate_with)\n",
        "pred_valid, actual_valid, vid_valid = get_predictions(model_type, model, features_valid, targets_valid, video_ids_valid, aggregate_with=aggregate_with)\n",
        "pred_test, actual_test, vid_test = get_predictions(model_type, model, features_test, targets_test, video_ids_test, aggregate_with=aggregate_with)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUy9FyIiVT2k"
      },
      "source": [
        "print(\"Validation spearman rank:\", stats.spearmanr(actual_valid, pred_valid)[0])\n",
        "print(\"Training spearman rank:\", stats.spearmanr(actual_train, pred_train)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqqHxLmTVT2l"
      },
      "source": [
        "predictions = np.concatenate([pred_train, pred_valid, pred_test])\n",
        "actuals = np.concatenate([actual_train, actual_valid, actual_test])\n",
        "video_ids = np.concatenate([vid_train, vid_valid, vid_test])\n",
        "in_training_set = np.array(np.concatenate([np.ones(len(pred_train)), np.zeros(len(pred_valid + pred_test))]), dtype=bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_gyFzqIVT2l"
      },
      "source": [
        "default_prediction = np.mean(predictions)\n",
        "for vid in train_data.index:\n",
        "    if vid not in video_ids:\n",
        "        print(f\"Adding vid {vid} with default prediction {default_prediction}\")\n",
        "        video_ids = np.append(video_ids, vid)\n",
        "        predictions = np.append(predictions, default_prediction)\n",
        "        in_training_set = np.append(in_training_set, vid in training_data.index)\n",
        "        actuals = np.append(actuals, train_data.loc[vid][target])\n",
        "        \n",
        "for vid in test_data.index:\n",
        "    if vid not in video_ids:\n",
        "        video_ids = np.append(video_ids, vid)\n",
        "        predictions = np.append(predictions, default_prediction)\n",
        "        in_training_set = np.append(in_training_set, False)\n",
        "        actuals = np.append(actuals, np.nan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM4RquHqVT2m"
      },
      "source": [
        "assert len(predictions) == len(actuals) == len(video_ids) == len(in_training_set) == len(train_data) + len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x71CciiVT2m"
      },
      "source": [
        "def save_predictions(model_name, video_ids, actuals, predictions, in_training_set, model_parameters, predictions_dir = PREDICTIONS_DIR):\n",
        "\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.mkdir(predictions_dir)\n",
        "        \n",
        "    model_data_dir = f\"{predictions_dir}/model_data.csv\"\n",
        "    if not os.path.exists(model_data_dir):\n",
        "        model_data = pd.DataFrame(columns=[\"name\", \"validation_spearman_rank\", \"type\", \"feature\", \"parameters\", \"predictions\", \"is_short_term\", \"seed\", \"notes\"])\n",
        "    else:\n",
        "        model_data = pd.read_csv(model_data_dir)\n",
        "        \n",
        "    model_dir = f\"{predictions_dir}/{model_name}\"\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.mkdir(model_dir)\n",
        "        \n",
        "    pred_filename = f\"{model_dir}/{'st' if IS_SHORT_TERM else 'lt'}-{RANDOM_SEED}.csv\"\n",
        "    \n",
        "    valid_spearman_rank, _ = stats.spearmanr(actuals[in_training_set], predictions[in_training_set])\n",
        "    \n",
        "    pred_data = pd.DataFrame({\n",
        "        \"video_id\": video_ids,\n",
        "        \"prediction\": predictions,\n",
        "        \"actual\": actuals,\n",
        "        \"in_training_set\": in_training_set\n",
        "    }).sort_values(\"video_id\")\n",
        "    \n",
        "    pred_data.to_csv(pred_filename, index = False)\n",
        "    \n",
        "    model_info = {\n",
        "        \"name\": model_name,\n",
        "        \"type\": model_type,\n",
        "        \"feature\": feature,\n",
        "        \"validation_spearman_rank\": np.around(spearman_rank,4),\n",
        "        \"parameters\": model_parameters,\n",
        "        \"predictions\": pred_filename,\n",
        "        \"notes\": NOTES,\n",
        "        \"seed\": RANDOM_SEED,\n",
        "        \"is_short_term\": IS_SHORT_TERM\n",
        "    }\n",
        "    \n",
        "    model_data.append(model_info, ignore_index = True).to_csv(model_data_dir, index = False)\n",
        "    \n",
        "    print(\"Saved model info and predictions: \", model_info)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kuiTJMTVT2m"
      },
      "source": [
        "assert SAVE_MODEL, \"Model was not saved.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVELX-jVT2n"
      },
      "source": [
        "save_predictions(model_name, video_ids, actuals, predictions, in_training_set, model_parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9JV1TPDVT2n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}