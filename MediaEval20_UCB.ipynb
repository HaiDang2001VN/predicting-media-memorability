{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "MediaEval20 - UCB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgsSrq5AVT1r"
      },
      "source": [
        "# Training workflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbjjPcz8h4nW",
        "outputId": "516d7da1-7819-4d35-a82f-dc0e05faac0c"
      },
      "source": [
        "%pip install -U fer"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fer\n",
            "  Downloading fer-21.0.5-py3-none-any.whl (810 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 810 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fer) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fer) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fer) (1.1.5)\n",
            "Collecting mtcnn>=0.1.1\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.1.2.30)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn>=0.1.1->fer) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fer) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fer) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (1.24.3)\n",
            "Installing collected packages: mtcnn, fer\n",
            "Successfully installed fer-21.0.5 mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AgkIHQZVT10"
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhbycpnhaRaV",
        "outputId": "c2147214-61b0-4340-c0cd-4d308dde0fde"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYWW9avoWFjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60208be-ec32-4673-f0b5-07b2155a25ee"
      },
      "source": [
        "%cd /content\n",
        "%rm -rf ucb\n",
        "!git clone https://github.com/HaiDang2001VN/predicting-media-memorability.git ucb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ucb'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 214 (delta 110), reused 164 (delta 60), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (214/214), 1.16 MiB | 9.29 MiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x70BiKP1ZXoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9678744-40d6-4b89-a0b8-19a3fe375ae6"
      },
      "source": [
        "%cd /content/ucb\n",
        "!unzip '/content/drive/MyDrive/HCMUS/Researchs/MediaEval21/Memo/Data/data.zip' -d ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Archive:  /content/drive/MyDrive/HCMUS/Researchs/MediaEval21/Memo/Data/data.zip\n",
            "   creating: ./development_set/\n",
            "  inflating: ./development_set/dev_short_term_annotations.csv  \n",
            "  inflating: ./development_set/dev_text_description.csv  \n",
            "  inflating: ./development_set/dev_video_urls.csv  \n",
            "   creating: ./testing_set/\n",
            "  inflating: ./testing_set/test_long_term_annotations.csv  \n",
            "  inflating: ./testing_set/test_short_term_annotations.csv  \n",
            "  inflating: ./testing_set/test_text_descriptions.csv  \n",
            "  inflating: ./testing_set/test_video_urls.csv  \n",
            "   creating: ./training_set/\n",
            "  inflating: ./training_set/train_long_term_annotations.csv  \n",
            "  inflating: ./training_set/train_scores.csv  \n",
            "  inflating: ./training_set/train_short_term_annotations.csv  \n",
            "  inflating: ./training_set/train_text_descriptions.csv  \n",
            "  inflating: ./training_set/train_video_urls.csv  \n",
            "ls: cannot access 'data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682RGXVjbgLX",
        "outputId": "d5b4ec55-9c39-42e0-ee3b-bf50aa52c685"
      },
      "source": [
        "%cd /content/ucb\n",
        "%ls -sla training_set\n",
        "%ls -sla testing_set\n",
        "%ls -sla development_set"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "total 2948\n",
            "   4 drwxr-xr-x 2 root root    4096 Nov 19  2021 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "   4 drwxr-xr-x 8 root root    4096 Nov 19 16:58 \u001b[01;34m..\u001b[0m/\n",
            " 592 -rw-r--r-- 1 root root  602173 Sep 14 01:15 train_long_term_annotations.csv\n",
            "  96 -rw-r--r-- 1 root root   94598 Sep 17 00:21 train_scores.csv\n",
            "1736 -rw-r--r-- 1 root root 1775597 Sep 14 01:10 train_short_term_annotations.csv\n",
            " 448 -rw-r--r-- 1 root root  458640 Sep 17 00:20 train_text_descriptions.csv\n",
            "  68 -rw-r--r-- 1 root root   66915 Sep 17 00:18 train_video_urls.csv\n",
            "total 2360\n",
            "   4 drwxr-xr-x 2 root root    4096 Nov 19  2021 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "   4 drwxr-xr-x 8 root root    4096 Nov 19 16:58 \u001b[01;34m..\u001b[0m/\n",
            " 696 -rw-r--r-- 1 root root  709011 Sep 14 01:21 test_long_term_annotations.csv\n",
            "1236 -rw-r--r-- 1 root root 1261867 Sep 14 01:20 test_short_term_annotations.csv\n",
            " 364 -rw-r--r-- 1 root root  371542 Aug 24 09:16 test_text_descriptions.csv\n",
            "  56 -rw-r--r-- 1 root root   56892 Sep 10 05:53 test_video_urls.csv\n",
            "total 3144\n",
            "   4 drwxr-xr-x 2 root root    4096 Nov 19  2021 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "   4 drwxr-xr-x 8 root root    4096 Nov 19 16:58 \u001b[01;34m..\u001b[0m/\n",
            "2168 -rw-r--r-- 1 root root 2217107 Oct 26 00:51 dev_short_term_annotations.csv\n",
            " 840 -rw-r--r-- 1 root root  857028 Oct 26 00:52 dev_text_description.csv\n",
            " 128 -rw-r--r-- 1 root root  129709 Oct 26 00:52 dev_video_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1ICO_ebbv8K",
        "outputId": "a687b226-3c04-4ec2-c218-ff733ec36d5e"
      },
      "source": [
        "%cd /content/ucb\n",
        "!python setup_train.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Opening training_set/train_video_urls.csv...\n",
            "Downloading videos: 100% 588/588 [01:02<00:00,  9.37it/s]\n",
            "Extracting audio: 100% 588/588 [00:51<00:00, 11.47it/s]\n",
            "Extracting 8 frames per video:  47% 275/588 [04:30<05:07,  1.02it/s]\u001b[0;36m[h264 @ 0x556054460000] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9200] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9200] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  54% 318/588 [05:15<05:59,  1.33s/it]\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463180] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463180] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463180] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463180] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9f80] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556052cb9b00] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463180] \u001b[0m\u001b[1;31mSEI type 5 size 192 truncated at 176\n",
            "Extracting 8 frames per video:  79% 463/588 [07:35<02:48,  1.35s/it]\u001b[0;36m[h264 @ 0x556054460d80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463600] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x556054463600] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video: 100% 588/588 [09:43<00:00,  1.01it/s]\n",
            "Finished setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2yEY246cHiZ",
        "outputId": "6e5cfa18-f4cb-421a-e007-f34416143327"
      },
      "source": [
        "%cd /content/ucb\n",
        "!python setup_test.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Opening testing_set/test_video_urls.csv...\n",
            "Downloading videos: 100% 500/500 [02:45<00:00,  3.02it/s]\n",
            "Extracting audio: 100% 500/500 [00:41<00:00, 12.07it/s]\n",
            "Extracting 8 frames per video:   3% 13/500 [00:11<06:38,  1.22it/s]\u001b[0;36m[h264 @ 0x55ddde050d00] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde04f680] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde04f680] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  15% 77/500 [01:14<06:26,  1.09it/s]\u001b[0;36m[h264 @ 0x55ddde050400] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde051a80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde051a80] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  50% 252/500 [04:14<03:36,  1.15it/s]\u001b[0;36m[h264 @ 0x55ddde04f200] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde051180] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde051180] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  70% 350/500 [05:55<02:34,  1.03s/it]\u001b[0;36m[h264 @ 0x55ddde050400] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde050d00] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde050d00] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  92% 461/500 [07:45<00:39,  1.02s/it]\u001b[0;36m[h264 @ 0x55ddde04ff80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde051a80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x55ddde051a80] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video: 100% 500/500 [08:29<00:00,  1.02s/it]\n",
            "Finished setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7nuekafCulF",
        "outputId": "67b018b8-78f9-4b76-8bb1-faab13a222b0"
      },
      "source": [
        "%cd /content/ucb\n",
        "!python setup_dev.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Opening development_set/dev_video_urls.csv...\n",
            "Downloading videos: 100% 1116/1116 [06:14<00:00,  2.98it/s]\n",
            "Extracting audio: 100% 1116/1116 [01:38<00:00, 11.37it/s]\n",
            "Extracting 8 frames per video:   2% 27/1116 [00:27<21:56,  1.21s/it]\u001b[0;36m[h264 @ 0x559c9ea92400] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x559c9ea93a80] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x559c9ea93a80] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video:  71% 789/1116 [13:28<06:05,  1.12s/it]\u001b[0;36m[h264 @ 0x559c9ea91b00] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x559c9ff26000] \u001b[0m\u001b[1;31mno frame!\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x559c9ff26000] \u001b[0m\u001b[1;31mno frame!\n",
            "Extracting 8 frames per video: 100% 1116/1116 [19:31<00:00,  1.05s/it]\n",
            "Finished setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldb5U0G6tOQb"
      },
      "source": [
        "# %cd /content/ucb/training_set\n",
        "# %rm -rf Features\n",
        "# %mkdir Features\n",
        "# %cp '/content/drive/MyDrive/HCMUS/AI/MedEval21/Memorability/2021-Predicting-Media-Memorability-Task/TRECVid Data/training_set/Features/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LalNeqz2pCZt",
        "outputId": "97e326b3-f88b-48c0-fc22-5d790f826d1e"
      },
      "source": [
        "%cd /content/ucb\n",
        "%rm -rf glove.6B\n",
        "%mkdir glove.6B\n",
        "!unzip '/content/drive/MyDrive/HCMUS/Researchs/MediaEval21/Memo/glove.6B.300d.txt.zip' -d glove.6B\n",
        "%ls -sla glove.6B"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "Archive:  /content/drive/MyDrive/HCMUS/Researchs/MediaEval21/Memo/glove.6B.300d.txt.zip\n",
            "  inflating: glove.6B/glove.6B.300d.txt  \n",
            "total 1013648\n",
            "      4 drwxr-xr-x 2 root root       4096 Nov 19 17:56 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "      4 drwxr-xr-x 9 root root       4096 Nov 19 17:56 \u001b[01;34m..\u001b[0m/\n",
            "1013640 -rw-r--r-- 1 root root 1037962819 Sep 22  2019 glove.6B.300d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvcbirUEnvkv",
        "outputId": "a75a66ec-733a-4693-d43e-6c48414069f2"
      },
      "source": [
        "%cd /content/ucb\n",
        "%mkdir training_set/Features\n",
        "%mkdir training_set/Features/GloVe\n",
        "%mkdir testing_set/Features\n",
        "%mkdir testing_set/Features/GloVe\n",
        "%mkdir development_set/Features\n",
        "%mkdir development_set/Features/GloVe\n",
        "!python extract_features.py"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ucb\n",
            "mkdir: cannot create directory ‘training_set/Features’: File exists\n",
            "mkdir: cannot create directory ‘training_set/Features/GloVe’: File exists\n",
            "mkdir: cannot create directory ‘testing_set/Features’: File exists\n",
            "mkdir: cannot create directory ‘testing_set/Features/GloVe’: File exists\n",
            "mkdir: cannot create directory ‘development_set/Features’: File exists\n",
            "mkdir: cannot create directory ‘development_set/Features/GloVe’: File exists\n",
            "Extract all features? (y/n) Otherwise extract on per-feature basis.n\n",
            "Extract text (GLoVe) features? (y/n)y\n",
            "\tFound 8032 captions for 2204 videos\n",
            "\tAvg num of captions per video: 3.644283121597096\n",
            "\tMax num of captions per video: 6\n",
            "\tMin num of captions per video: 2\n",
            "Max sequence length: 86\n",
            "Min sequence length: 2\n",
            "Avg sequence length: 17.88969123505976\n",
            "Fitting tokenizer...\n",
            "Extracting GLoVe features from training_set/train_text_descriptions.csv...\n",
            "2021-11-19 18:00:39.759923: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-11-19 18:00:40.469449: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 225388800 exceeds 10% of free system memory.\n",
            "100% 2184/2184 [00:37<00:00, 57.78it/s]\n",
            "Extracting GLoVe features from development_set/dev_text_description.csv...\n",
            "2021-11-19 18:01:40.084574: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 418785600 exceeds 10% of free system memory.\n",
            "100% 4058/4058 [01:10<00:00, 57.34it/s]\n",
            "Extracting GLoVe features from testing_set/test_text_descriptions.csv...\n",
            "2021-11-19 18:03:09.807229: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 184728000 exceeds 10% of free system memory.\n",
            "100% 1790/1790 [00:31<00:00, 57.29it/s]\n",
            "Saving tokenizer at features//caption_tokenizer.pickle\n",
            "Finished GLoVe feature extraction.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ni1n5l3VT15"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "import features.config as fconf"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfoIgxf_VT18"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzB82VygVT19"
      },
      "source": [
        "PREDICTIONS_DIR = \"predictions\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0jKz4zkVT1-"
      },
      "source": [
        "SAVE_MODEL = True\n",
        "IS_SHORT_TERM = True\n",
        "\n",
        "USE_DEV_SET = True\n",
        "USE_TRAIN_SET = True"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLWvk5umVT2A"
      },
      "source": [
        "RANDOM_SEED = 42"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f41oGQocVT2B"
      },
      "source": [
        "target = \"m_75\" if IS_SHORT_TERM else \"part_2_scores\"\n",
        "feature = \"glove\"\n",
        "model_type = \"gru\"\n",
        "aggregate_with = np.median"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Efes_kVT2C"
      },
      "source": [
        "model_name = f\"{feature}_{model_type}\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJoXdSvRVT2E"
      },
      "source": [
        "model_parameters = {\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"use_dev_set\": USE_DEV_SET,\n",
        "}\n",
        "\n",
        "if model_type == \"gru\":\n",
        "    model_parameters[\"hidden_dim\"] = 64\n",
        "    model_parameters[\"learning_rate\"] = 1e-3\n",
        "    model_parameters[\"num_epochs\"] = 150\n",
        "    model_parameters[\"batch_size\"] = 64\n",
        "    model_parameters[\"gru_units\"] = 64\n",
        "    model_parameters[\"gru_dropout\"] = 0.8"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwll8cjrVT2N"
      },
      "source": [
        "NOTES = \"\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNQuacdRVT2P"
      },
      "source": [
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxy1ZO5QVT2P"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Extracted features, scores, metadata, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-LPx_W0VT2R"
      },
      "source": [
        "testing_set_data = pd.read_csv(\"testing_set/test_video_urls.csv\").set_index(\"video_id\")\n",
        "\n",
        "if USE_TRAIN_SET:\n",
        "    training_set_data = pd.read_csv(\"training_set/train_video_urls.csv\").set_index(\"video_id\")\n",
        "\n",
        "if USE_DEV_SET:\n",
        "    development_set_data = pd.read_csv(\"development_set/dev_video_urls.csv\").set_index(\"video_id\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLLbqhvrVT2R"
      },
      "source": [
        "from features.video import load_C3D_features\n",
        "from features.image import load_ResNet152_features, load_LBP_features, load_HOG_features\n",
        "from features.audio import load_VGGish_features\n",
        "from features.text import load_GloVe_features\n",
        "from features.emotion import load_Emotion_features, extract_emotions\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJk0RQ8lVT2T"
      },
      "source": [
        "def add_features_to_df(dfs, set_names, label, feature_dir, load_func):\n",
        "    for df, set_name in zip(dfs, set_names):\n",
        "        df[label] = load_func(df.index, fconf.set_dataset(set_name, feature_dir))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NcFNgmcVT2T"
      },
      "source": [
        "dfs = [testing_set_data]\n",
        "set_names = [\"testing_set\"]\n",
        "\n",
        "if USE_TRAIN_SET:\n",
        "    dfs.append(training_set_data)\n",
        "    set_names.append(\"training_set\")\n",
        "\n",
        "if USE_DEV_SET:\n",
        "    dfs.append(development_set_data)\n",
        "    set_names.append(\"development_set\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoZIqjMYVT2U"
      },
      "source": [
        "# Emotion\n",
        "if feature == \"emotion\":\n",
        "    add_features_to_df(dfs, set_names, \"emotion\",\n",
        "                      fconf.EMOTION_FEATURE_DIR, load_Emotion_features)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7yBbEURVT2U"
      },
      "source": [
        "# LBP\n",
        "if feature == \"lbp\":\n",
        "    add_features_to_df(dfs, set_names, \"lbp\",\n",
        "                      fconf.LBP_FEATURE_DIR, load_LBP_features)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2TDApJVT2V"
      },
      "source": [
        "# HOG\n",
        "if feature == \"hog\":\n",
        "    add_features_to_df(dfs, set_names, \"hog\",\n",
        "                      fconf.HOG_FEATURE_DIR, load_HOG_features)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzUTraoVVT2W"
      },
      "source": [
        "# ResNet152\n",
        "if feature == \"resnet152\":\n",
        "    add_features_to_df(dfs, set_names, \"resnet152\",\n",
        "                      fconf.RESNET152_FEATURE_DIR, load_ResNet152_features)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sutpUOJwVT2X"
      },
      "source": [
        "# C3D\n",
        "if feature == \"c3d\":\n",
        "    add_features_to_df(dfs, set_names, \"c3d\",\n",
        "                      fconf.C3D_FEATURE_DIR, load_C3D_features)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoLdQ3Y4VT2X"
      },
      "source": [
        "# VGGish\n",
        "if feature == \"vggish\":\n",
        "    add_features_to_df(dfs, set_names, \"vggish\",\n",
        "                      fconf.VGGISH_FEATURE_DIR, load_VGGish_features)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfOQDK2VT2X"
      },
      "source": [
        "# GLoVE\n",
        "if feature == \"glove\":\n",
        "    add_features_to_df(dfs, set_names, \"glove\",\n",
        "                      fconf.GLOVE_FEATURE_DIR, load_GloVe_features)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIqAwOZqaXfk",
        "outputId": "3225871d-0e66-4082-cb7d-865af6add428"
      },
      "source": [
        "print(training_set_data.shape, development_set_data.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(588, 2) (1116, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN4wg9pDVT2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308c6a19-3928-4495-8d7d-ed6f9133f427"
      },
      "source": [
        "test_data = testing_set_data\n",
        "\n",
        "if USE_DEV_SET and USE_TRAIN_SET:\n",
        "    train_data = pd.concat([training_set_data, development_set_data])\n",
        "    print(train_data.shape)\n",
        "elif USE_DEV_SET and not USE_TRAIN_SET:\n",
        "    train_data = development_set_data\n",
        "elif USE_TRAIN_SET and not USE_DEV_SET:\n",
        "    train_data = training_set_data\n",
        "else:\n",
        "    raise ValueError(\"train_data is empty\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1704, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yXl1lBvVT2Y"
      },
      "source": [
        "## Target Prep\n",
        "\n",
        "Khosla points out that the memorability score used in Isola's paper did not take into account the memory retention duration.\n",
        "Cohendet utilized the same idea as Khosla, which involved a decay rate\n",
        "\n",
        "$$\\alpha \\leftarrow \n",
        "\\frac{\\sum^N_{i=1}\\frac{1}{n^{(i)}} \\sum^{n^{(i)}}_{j=1} \\log(\\frac{t^{(i)}_j}{T})[x^{(i)}_j - m^{(i)}_T] }\n",
        "{\\sum^N_{i=1}\\frac{1}{n^{(i)}} \\sum^{n^{(i)}}_{j=1}[ \\log(\\frac{t^{(i)}_j}{T})]^2}\n",
        "$$\n",
        "\n",
        "to calculate memorability \n",
        "$$\n",
        "m_T^{(i)} \\leftarrow\n",
        "\\frac{1}{n^{(i)}} \\sum^{n^{(i)}}_{j=1}[x^{(i)}_j - \\alpha \\log(\\frac{t_j^{(i)}}{T})]\n",
        "$$\n",
        "\n",
        "where we have $n^{(i)}$ observations for image $i$ given by $x^{(i)} \\in {0,1}$ and $t^{(i)}_j$ where $x_j=1$  implies that the image repeat was correctly detected when it shown after time $t_j$\n",
        "\n",
        "IDEA: potentially explore calculating $\\alpha$ per user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woV8sDXFVT2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec150a6d-9a1e-44ea-bec1-104544311065"
      },
      "source": [
        "from target_augmentation import add_position_delta, calculate_alpha_and_memorability\n",
        "print(train_data.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1704, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT5iAGPNVT2Z"
      },
      "source": [
        "if USE_DEV_SET and USE_TRAIN_SET:\n",
        "    annotations = add_position_delta(pd.concat([\n",
        "        pd.read_csv(\"training_set/train_short_term_annotations.csv\"),\n",
        "        pd.read_csv(\"development_set/dev_short_term_annotations.csv\")\n",
        "    ]))\n",
        "elif USE_TRAIN_SET and not USE_DEV_SET:\n",
        "    annotations = add_position_delta(pd.read_csv(\"training_set/train_short_term_annotations.csv\"))\n",
        "elif USE_DEV_SET and not USE_TRAIN_SET:\n",
        "    annotations = add_position_delta(pd.read_csv(\"development_set/dev_short_term_annotations.csv\"))\n",
        "else:\n",
        "    raise ValueError(\"annotations is empty\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQtcLqlAaGU_",
        "outputId": "7a2da3c4-9b48-4325-e864-11cfdc66b68d"
      },
      "source": [
        "annotations['video_id'].unique().shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1706,)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fK6Wy9KlsUB",
        "outputId": "120b5abf-0f7f-450b-8087-45aef82b5436"
      },
      "source": [
        "print(\"Average t:\", np.mean(annotations[\"t\"]))\n",
        "\n",
        "# We use approximately the average_t to calculate T as the memorability in question\n",
        "big_t = int(np.around(np.mean(annotations[\"t\"])))\n",
        "label = f\"m_{big_t}\"\n",
        "print(f\"Calculating adjusted value for {label}\")\n",
        "alpha, adjusted_score = calculate_alpha_and_memorability(annotations, T = big_t)\n",
        "train_data[label] = adjusted_score\n",
        "test_data[label] = np.nan\n",
        "print(f\"Alpha: {alpha}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average t: 75.07737933839479\n",
            "Calculating adjusted value for m_75\n",
            "Alpha: -0.04299253751091441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LUote5imBH-",
        "outputId": "ee84a473-a4ca-4f30-fd8f-bcf7192934b3"
      },
      "source": [
        "train_scores = pd.read_csv('training_set/train_scores.csv')\n",
        "dev_scores = pd.read_csv('development_set/dev_scores.csv')\n",
        "train_scores = pd.concat([train_scores, dev_scores])\n",
        "train_scores.info()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1704 entries, 0 to 1115\n",
            "Data columns (total 8 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   video_id                      1704 non-null   int64  \n",
            " 1   video_url                     1704 non-null   object \n",
            " 2   annotations_short_term        1704 non-null   int64  \n",
            " 3   annotations_long_term         1704 non-null   int64  \n",
            " 4   scores_raw_short_term         1704 non-null   float64\n",
            " 5   scores_raw_long_term          1704 non-null   float64\n",
            " 6   scores_normalized_short_term  1704 non-null   float64\n",
            " 7   decay_alpha                   1704 non-null   float64\n",
            "dtypes: float64(4), int64(3), object(1)\n",
            "memory usage: 119.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkbAUg_saRno",
        "outputId": "0ab06ab9-5c59-412c-9d62-e854b4050562"
      },
      "source": [
        "train_data[label].shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1704,)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "iBPqAq9jVT2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "5b223185-c917-4bd2-b9f0-4f2564526024"
      },
      "source": [
        "train_data = train_data.merge(train_scores[['video_id', 'scores_raw_short_term']], on='video_id')\n",
        "target_diff = train_data[\"scores_raw_short_term\"] - train_data[label]\n",
        "print(\"Avg diff:\", np.mean(target_diff))\n",
        "print(\"Max diff:\", np.max(target_diff))\n",
        "print(\"Min diff:\", np.min(target_diff))\n",
        "plt.scatter(train_data[\"scores_raw_short_term\"], train_data[label])\n",
        "plt.xlabel(\"Original memorability score\")\n",
        "plt.ylabel(f\"Adjusted memorability score ({label})\")\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg diff: 0.0010520242387328691\n",
            "Max diff: 0.011141621895131348\n",
            "Min diff: -0.00878440335342523\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_eo8ho-VT2a"
      },
      "source": [
        "## Data Prep\n",
        "\n",
        "Building datasets\n",
        "\n",
        "potentially weighting samples based on annotations?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hohUg9oHVT2b"
      },
      "source": [
        "from train import split_training, build_matrixes"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKoy3vrXVT2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87c82f7-2f27-4863-dbb6-02da09e06cb0"
      },
      "source": [
        "training_data, validation_data = split_training(train_data)\n",
        "print(\"training:\",len(training_data))\n",
        "print(\"validation:\", len(validation_data))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training: 1363\n",
            "validation: 341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tHgYo_MVT2c"
      },
      "source": [
        "#### Pick Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA2M2fm2VT2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8a8409-a804-4fc1-a5b5-83ee952ba9de"
      },
      "source": [
        "features_train, targets_train, video_ids_train = build_matrixes(training_data, target_name = target, feature_name = feature)\n",
        "features_valid, targets_valid, video_ids_valid = build_matrixes(validation_data, target_name = target, feature_name = feature)\n",
        "features_test, targets_test, video_ids_test = build_matrixes(test_data, target_name = target, feature_name = feature, is_test = True)\n",
        "\n",
        "\n",
        "print(\"num videos in training set:\", len(training_data))\n",
        "print(\"num videos in validation set:\", len(validation_data))\n",
        "print(\"num videos in test set:\", len(test_data))\n",
        "print(\"features_train shape:\", features_train.shape)\n",
        "print(\"targets_train shape:\", targets_train.shape)\n",
        "print(\"features_valid shape:\", features_valid.shape)\n",
        "print(\"targets_valid shape:\", targets_valid.shape)\n",
        "total_features = len(features_train) + len(features_valid)\n",
        "unique, count = np.unique(np.concatenate([video_ids_valid, video_ids_train]), return_counts=True)\n",
        "print(\"Total features:\", total_features)\n",
        "print(\"Total videos:\", len(unique))\n",
        "print(\"Avg features per video:\", total_features / len(unique))\n",
        "print(\"Min features per video:\", min(count))\n",
        "print(\"Max features per video:\", max(count))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num videos in training set: 1363\n",
            "num videos in validation set: 341\n",
            "num videos in test set: 500\n",
            "features_train shape: (5019, 86, 300)\n",
            "targets_train shape: (5019, 1)\n",
            "features_valid shape: (1223, 86, 300)\n",
            "targets_valid shape: (1223, 1)\n",
            "Total features: 6242\n",
            "Total videos: 1704\n",
            "Avg features per video: 3.6631455399061035\n",
            "Min features per video: 2\n",
            "Max features per video: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyNQdNwmVT2g"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "z9sG6MZyVT2g"
      },
      "source": [
        "from train import train_model       "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZUjx7dnUVT2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5075c935-534a-4ebf-9b7a-f6a740b31e55"
      },
      "source": [
        "model = train_model(model_type, features_train, targets_train, features_valid, targets_valid, model_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input dimensions: (86, 300)\n",
            "hidden dimension: 64\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/150\n",
            "157/157 [==============================] - 87s 517ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0950 - mape: 12.3366 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1129 - val_mape: 13.5219\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 80s 507ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0921 - mape: 11.9746 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.1125 - val_mape: 13.4681\n",
            "Epoch 3/150\n",
            " 83/157 [==============>...............] - ETA: 36s - loss: 0.0135 - mse: 0.0135 - mae: 0.0916 - mape: 12.0200"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QboEapcKVT2h"
      },
      "source": [
        "## Test\n",
        "\n",
        "Spearman's rank correlation, ROC curves, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2ciKpKVT2h"
      },
      "source": [
        "from train import get_predictions\n",
        "\n",
        "predictions, actuals, _ = get_predictions(\n",
        "    model_type, model, features_valid, targets_valid, video_ids_valid, aggregate_with=aggregate_with\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "doN3okHpVT2i"
      },
      "source": [
        "spearman_rank, _ = stats.spearmanr(actuals, predictions)\n",
        "print(\"SPEARMAN RANK:\",spearman_rank)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(8,8))\n",
        "min_mem = min(np.min(actuals), np.min(predictions))\n",
        "max_mem = max(np.max(actuals), np.max(predictions))\n",
        "plt.scatter(actuals, predictions, label = f\"Spearman rank correlation = {spearman_rank}\")\n",
        "# plt.plot([min_mem, max_mem], [min_mem, max_mem], label=\"1 to 1\")\n",
        "plt.title(f\"actual {target} vs predicted {target}\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"predictions\")\n",
        "plt.xlabel(\"actual\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zaUtVaJVT2j"
      },
      "source": [
        "# Saving Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trT0ONvIVT2k"
      },
      "source": [
        "pred_train, actual_train, vid_train = get_predictions(model_type, model, features_train, targets_train, video_ids_train, aggregate_with=aggregate_with)\n",
        "pred_valid, actual_valid, vid_valid = get_predictions(model_type, model, features_valid, targets_valid, video_ids_valid, aggregate_with=aggregate_with)\n",
        "pred_test, actual_test, vid_test = get_predictions(model_type, model, features_test, targets_test, video_ids_test, aggregate_with=aggregate_with)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUy9FyIiVT2k"
      },
      "source": [
        "print(\"Validation spearman rank:\", stats.spearmanr(actual_valid, pred_valid)[0])\n",
        "print(\"Training spearman rank:\", stats.spearmanr(actual_train, pred_train)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqqHxLmTVT2l"
      },
      "source": [
        "predictions = np.concatenate([pred_train, pred_valid, pred_test])\n",
        "actuals = np.concatenate([actual_train, actual_valid, actual_test])\n",
        "video_ids = np.concatenate([vid_train, vid_valid, vid_test])\n",
        "in_training_set = np.array(np.concatenate([np.ones(len(pred_train)), np.zeros(len(pred_valid + pred_test))]), dtype=bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_gyFzqIVT2l"
      },
      "source": [
        "default_prediction = np.mean(predictions)\n",
        "for vid in train_data.index:\n",
        "    if vid not in video_ids:\n",
        "        print(f\"Adding vid {vid} with default prediction {default_prediction}\")\n",
        "        video_ids = np.append(video_ids, vid)\n",
        "        predictions = np.append(predictions, default_prediction)\n",
        "        in_training_set = np.append(in_training_set, vid in training_data.index)\n",
        "        actuals = np.append(actuals, train_data.loc[vid][target])\n",
        "        \n",
        "for vid in test_data.index:\n",
        "    if vid not in video_ids:\n",
        "        video_ids = np.append(video_ids, vid)\n",
        "        predictions = np.append(predictions, default_prediction)\n",
        "        in_training_set = np.append(in_training_set, False)\n",
        "        actuals = np.append(actuals, np.nan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM4RquHqVT2m"
      },
      "source": [
        "assert len(predictions) == len(actuals) == len(video_ids) == len(in_training_set) == len(train_data) + len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x71CciiVT2m"
      },
      "source": [
        "def save_predictions(model_name, video_ids, actuals, predictions, in_training_set, model_parameters, predictions_dir = PREDICTIONS_DIR):\n",
        "\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.mkdir(predictions_dir)\n",
        "        \n",
        "    model_data_dir = f\"{predictions_dir}/model_data.csv\"\n",
        "    if not os.path.exists(model_data_dir):\n",
        "        model_data = pd.DataFrame(columns=[\"name\", \"validation_spearman_rank\", \"type\", \"feature\", \"parameters\", \"predictions\", \"is_short_term\", \"seed\", \"notes\"])\n",
        "    else:\n",
        "        model_data = pd.read_csv(model_data_dir)\n",
        "        \n",
        "    model_dir = f\"{predictions_dir}/{model_name}\"\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.mkdir(model_dir)\n",
        "        \n",
        "    pred_filename = f\"{model_dir}/{'st' if IS_SHORT_TERM else 'lt'}-{RANDOM_SEED}.csv\"\n",
        "    \n",
        "    valid_spearman_rank, _ = stats.spearmanr(actuals[in_training_set], predictions[in_training_set])\n",
        "    \n",
        "    pred_data = pd.DataFrame({\n",
        "        \"video_id\": video_ids,\n",
        "        \"prediction\": predictions,\n",
        "        \"actual\": actuals,\n",
        "        \"in_training_set\": in_training_set\n",
        "    }).sort_values(\"video_id\")\n",
        "    \n",
        "    pred_data.to_csv(pred_filename, index = False)\n",
        "    \n",
        "    model_info = {\n",
        "        \"name\": model_name,\n",
        "        \"type\": model_type,\n",
        "        \"feature\": feature,\n",
        "        \"validation_spearman_rank\": np.around(spearman_rank,4),\n",
        "        \"parameters\": model_parameters,\n",
        "        \"predictions\": pred_filename,\n",
        "        \"notes\": NOTES,\n",
        "        \"seed\": RANDOM_SEED,\n",
        "        \"is_short_term\": IS_SHORT_TERM\n",
        "    }\n",
        "    \n",
        "    model_data.append(model_info, ignore_index = True).to_csv(model_data_dir, index = False)\n",
        "    \n",
        "    print(\"Saved model info and predictions: \", model_info)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kuiTJMTVT2m"
      },
      "source": [
        "assert SAVE_MODEL, \"Model was not saved.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVELX-jVT2n"
      },
      "source": [
        "save_predictions(model_name, video_ids, actuals, predictions, in_training_set, model_parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9JV1TPDVT2n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}