{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_DIR = \"training_set/predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv(f\"{PREDICTIONS_DIR}/model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>validation_spearman_rank</th>\n",
       "      <th>parameters</th>\n",
       "      <th>predictions</th>\n",
       "      <th>notes</th>\n",
       "      <th>is_short_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet152_SVR</td>\n",
       "      <td>0.2408</td>\n",
       "      <td>{'RANDOM_SEED': 1}</td>\n",
       "      <td>training_set/predictions/ResNet152_SVR/0.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C3D_SVR</td>\n",
       "      <td>0.1658</td>\n",
       "      <td>{'RANDOM_SEED': 1}</td>\n",
       "      <td>training_set/predictions/C3D_SVR/0.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGGish_SVR</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>{'RANDOM_SEED': 1}</td>\n",
       "      <td>training_set/predictions/VGGish_SVR/0.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  validation_spearman_rank          parameters  \\\n",
       "0  ResNet152_SVR                    0.2408  {'RANDOM_SEED': 1}   \n",
       "1        C3D_SVR                    0.1658  {'RANDOM_SEED': 1}   \n",
       "2     VGGish_SVR                    0.1044  {'RANDOM_SEED': 1}   \n",
       "\n",
       "                                    predictions  notes  is_short_term  \n",
       "0  training_set/predictions/ResNet152_SVR/0.csv    NaN          False  \n",
       "1        training_set/predictions/C3D_SVR/0.csv    NaN          False  \n",
       "2     training_set/predictions/VGGish_SVR/0.csv    NaN          False  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(prediction_files):\n",
    "    preds = []\n",
    "    actual = None\n",
    "    is_training = None\n",
    "    \n",
    "    for pred_file in prediction_files:\n",
    "        prediction_data = pd.read_csv(pred_file)\n",
    "        print(len(prediction_data))\n",
    "        if actual is None:\n",
    "            actual = np.array(prediction_data[\"actual\"])\n",
    "            is_training = np.array(prediction_data[\"in_training_set\"])\n",
    "        assert np.allclose(actual, np.array(prediction_data[\"actual\"]))\n",
    "        assert np.equal(is_training, np.array(prediction_data[\"in_training_set\"])).all()\n",
    "        \n",
    "        \n",
    "        preds.append(prediction_data[\"prediction\"])\n",
    "        \n",
    "    return preds, actual, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "590\n",
      "590\n"
     ]
    }
   ],
   "source": [
    "preds, actual, is_training = get_predictions(model_data[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_training = [pred[is_training] for pred in preds]\n",
    "actual_training = actual[is_training]\n",
    "preds_validation = [pred[np.logical_not(is_training)] for pred in preds]\n",
    "actual_validation = actual[np.logical_not(is_training)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(preds_training).T\n",
    "y_train = np.array(actual_training)\n",
    "X_test = np.array(preds_validation).T\n",
    "y_test = np.array(actual_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((472, 3), (472,))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = Lasso(normalize=True, alpha = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, normalize=True)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0836491 , 0.15428462, 0.        ])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87536924 0.12463076 0.        ]\n"
     ]
    }
   ],
   "source": [
    "normalize = lambda arr: arr / np.sum(arr)\n",
    "ensemble.coef_ = normalize(ensemble.coef_)\n",
    "print(ensemble.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_predictions = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26192119611860387\n"
     ]
    }
   ],
   "source": [
    "spearman_rank, _ = stats.spearmanr(y_test, ensemble_test_predictions)\n",
    "print(spearman_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-mem",
   "language": "python",
   "name": "video-mem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
