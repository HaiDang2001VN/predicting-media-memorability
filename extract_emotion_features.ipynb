{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tony/anaconda3/envs/video-mem/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from fer import FER\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_FEATURE_DIR = \"training_set/Features/Emotion\"\n",
    "FRAMES_DIR = \"training_set/N-Frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_emotion_vector(emotions_likelihood, max_faces, emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']):\n",
    "    num_faces_frame = len(emotions_likelihood)\n",
    "    if num_faces_frame > max_faces: #cap the number of faces\n",
    "        print(f\"Video '{video_id}' has {num_faces_frame}, while max_faces is {max_faces}\")\n",
    "        num_faces_frame = max_faces \n",
    "\n",
    "    frame_feature = []\n",
    "    for face in range(num_faces_frame):            # detected faces\n",
    "        frame_feature.append(np.array([emotions_likelihood[face][\"emotions\"][emotion] for emotion in emotions]))\n",
    "    for face in range(num_faces_frame, max_faces): # no faces detected, fill with zero\n",
    "        frame_feature.append(np.array(np.zeros(len(emotions))))\n",
    "        \n",
    "    emotion_vector = np.concatenate(frame_feature)\n",
    "    return emotion_vector\n",
    "\n",
    "def print_extraction_statistics(num_faces_frames, num_faces_videos):\n",
    "    num_faces_frames = np.array(num_faces_frames)\n",
    "    num_faces_videos = np.array(num_faces_videos)\n",
    "    print(f\"{np.sum(num_faces_frames > 0)} / {len(num_faces_frames)} frames have faces\")\n",
    "    print(f\"{np.sum(num_faces_videos > 0)} / {len(num_faces_videos)} vidoes have faces\")\n",
    "    print(\"Avg num of faces per frame:\", np.mean(num_faces_frames))\n",
    "    print(\"Max num of faces per frame:\", np.max(num_faces_frames))\n",
    "    print(\"Min num of faces per frame:\", np.min(num_faces_frames))\n",
    "    print(\"Avg num of faces per video:\", np.mean(num_faces_videos))\n",
    "    print(\"Max num of faces per video:\", np.max(num_faces_videos))\n",
    "    print(\"Min num of faces per video:\", np.min(num_faces_videos))\n",
    "    print(\"Avg num of faces per frame for frames with at least 1 face:\", \n",
    "          np.mean(num_faces_frames[num_faces_frames > 1]))\n",
    "    print(\"Avg num of faces per video for videos with at least 1 face:\", \n",
    "          np.mean(num_faces_videos[num_faces_videos > 1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tony/anaconda3/envs/video-mem/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-11-2020:12:18:12,910 WARNING  [deprecation.py:317] From /home/tony/anaconda3/envs/video-mem/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4720,)\n",
      "(590,)\n",
      "1563 / 4720 frames have faces\n",
      "421 / 590 vidoes have faces\n",
      "Avg num of faces per frame: 0.4417372881355932\n",
      "Max num of faces per frame: 8\n",
      "Min num of faces per frame: 0\n",
      "Avg num of faces per video: 3.5338983050847457\n",
      "Max num of faces per video: 55\n",
      "Min num of faces per video: 0\n",
      "Avg num of faces per frame for frames with at least 1 face: 2.5535714285714284\n",
      "Avg num of faces per video for videos with at least 1 face: 6.057750759878419\n"
     ]
    }
   ],
   "source": [
    "def extract_emotions(video_ids = None, frame_path = FRAMES_DIR, feature_dir = EMOTION_FEATURE_DIR, max_faces = 8):\n",
    "    if video_ids is None:\n",
    "        video_ids = np.sort(os.listdir(frame_path))\n",
    "        \n",
    "    if not os.path.exists(feature_dir):\n",
    "        os.mkdir(feature_dir)\n",
    "    \n",
    "    failed = [] \n",
    "    detector = FER()\n",
    "    \n",
    "    num_faces_frames = []\n",
    "    num_faces_videos = []\n",
    "    \n",
    "    # Extract emotion features\n",
    "    for video_id in video_ids: \n",
    "        \n",
    "        video_features_filename = f\"{feature_dir}/{int(video_id)}.csv\"\n",
    "        if os.path.exists(video_features_filename):\n",
    "            continue\n",
    "            \n",
    "        video_features = []\n",
    "        num_faces_video = []\n",
    "        \n",
    "        for filename in os.listdir(f\"{frame_path}/{video_id}\"):\n",
    "            emotions_likelihood = detector.detect_emotions(cv2.imread(f\"{frame_path}/{video_id}/{filename}\"))\n",
    "            \n",
    "            num_faces_frame = len(emotions_likelihood)\n",
    "            num_faces_frames.append(num_faces_frame)\n",
    "            num_faces_video.append(num_faces_frame)\n",
    "            \n",
    "            if num_faces_frame > 0: # Detected at least one face\n",
    "                video_features.append(build_emotion_vector(emotions_likelihood, max_faces))\n",
    "            else:\n",
    "                failed.append(f\"{video_id}/{filename}\")\n",
    "                \n",
    "            \n",
    "        num_faces_videos.append(np.sum(num_faces_video))\n",
    "        \n",
    "        if video_features:\n",
    "            video_features = np.array(video_features)\n",
    "            np.savetxt(video_features_filename, video_features)\n",
    "            \n",
    "    print_extraction_statistics(num_faces_frames, num_faces_videos)\n",
    "    \n",
    "    return failed\n",
    "\n",
    "failed = extract_emotions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-mem",
   "language": "python",
   "name": "video-mem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
