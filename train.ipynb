{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "RANDOM_SEED = 1\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "print(f\"CUDA: {CUDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Extracted features, scores, metadata, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_set/scores.csv\").set_index(\"video_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://mtc.cdn.vine.co/r/videos/2F3C4AC3441177607211065782272_315002b18b6.1.5.17458932009632344785.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(data.iloc[22][\"video_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_C3D_features(video_ids, path =\"training_set/Features/C3D/\"):\n",
    "    features = []\n",
    "    for video_id in video_ids:\n",
    "        filename = f\"{path}{f'{video_id}'.zfill(5)}.mp4.csv\"\n",
    "        features.append(np.loadtxt(filename, delimiter=\",\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"c3d\"] = load_C3D_features(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "Building datasets\n",
    "\n",
    "potentially weighting samples based on annotations?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_url</th>\n",
       "      <th>ann_1</th>\n",
       "      <th>ann_2</th>\n",
       "      <th>part_1_scores</th>\n",
       "      <th>part_2_scores</th>\n",
       "      <th>c3d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://mtc.cdn.vine.co/r/videos_h264high/9EB0...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.1541, 0.3501, 0.1796, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://mtc.cdn.vine.co/r/videos_h264high/A8B3...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[0.6788, 0.2429, 0.0, 0.0, 0.8737, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://mtc.cdn.vine.co/r/videos/267829AEFA128...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[0.511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://mtc.cdn.vine.co/r/videos_h264high/B974...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.363...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>https://mtc.cdn.vine.co/r/videos_h264high/C4D6...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.43</td>\n",
       "      <td>[0.4755, 0.0, 0.0153, 0.0, 0.0, 0.1077, 0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  video_url  ann_1  ann_2  \\\n",
       "video_id                                                                    \n",
       "8         https://mtc.cdn.vine.co/r/videos_h264high/9EB0...      5      3   \n",
       "26        https://mtc.cdn.vine.co/r/videos_h264high/A8B3...      6      4   \n",
       "33        https://mtc.cdn.vine.co/r/videos/267829AEFA128...      7      4   \n",
       "46        https://mtc.cdn.vine.co/r/videos_h264high/B974...      6      4   \n",
       "64        https://mtc.cdn.vine.co/r/videos_h264high/C4D6...      6      7   \n",
       "\n",
       "          part_1_scores  part_2_scores  \\\n",
       "video_id                                 \n",
       "8                  1.00           1.00   \n",
       "26                 1.00           0.75   \n",
       "33                 0.71           0.75   \n",
       "46                 1.00           0.25   \n",
       "64                 0.83           0.43   \n",
       "\n",
       "                                                        c3d  \n",
       "video_id                                                     \n",
       "8         [0.0, 0.0, 0.0, 0.0, 0.1541, 0.3501, 0.1796, 0...  \n",
       "26        [0.6788, 0.2429, 0.0, 0.0, 0.8737, 0.0, 0.0, 0...  \n",
       "33        [0.511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "46        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.363...  \n",
       "64        [0.4755, 0.0, 0.0153, 0.0, 0.0, 0.1077, 0.0, 0...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training(data: pd.DataFrame, shuffle=True, split=0.8):\n",
    "    ids = np.random.permutation(list(data.index)) if shuffle else list(data.index)\n",
    "    split_index = int(len(ids) * split)\n",
    "    return data.loc[ids[:split_index]], data.loc[ids[split_index:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 118\n"
     ]
    }
   ],
   "source": [
    "train, valid = split_training(data)\n",
    "print(len(train), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrixes(data: pd.DataFrame, targets, features, dtype=\"double\"):\n",
    "    feature_matrix = [np.concatenate(list(row_features), axis=None) \n",
    "                      for row_features in zip(*[list(data[feature]) for feature in features])]\n",
    "    target_matrix = [np.concatenate(row_targets, axis = None) \n",
    "                     for row_targets in zip(*[list(data[target]) for target in targets])]\n",
    "    return np.array(feature_matrix, dtype=dtype), np.array(target_matrix, dtype=dtype)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 118 472 118\n"
     ]
    }
   ],
   "source": [
    "targets = [\"part_1_scores\", \"part_2_scores\"]\n",
    "features = [\"c3d\"]\n",
    "\n",
    "features_train, targets_train = build_matrixes(train, targets = targets, features = features)\n",
    "features_valid, targets_valid = build_matrixes(valid, targets = targets, features = features)\n",
    "\n",
    "print(len(features_train), len(features_valid), len(targets_train), len(targets_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 118\n"
     ]
    }
   ],
   "source": [
    "data_train = FlatDataset(features_train, targets_train)\n",
    "data_valid = FlatDataset(features_valid, targets_valid)\n",
    "print(len(data_train), len(data_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 2\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(features_train[0])\n",
    "output_dim = len(targets_train[0])\n",
    "print(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = 1024):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerNet(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if CUDA else torch.device(\"cpu\")\n",
    "model = model.double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = torch.utils.data.DataLoader(data_valid, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, dataloader_valid, loss_fn, optimizer, scheduler, device):\n",
    "    \n",
    "    for is_training in [True, False]: # Epoch is a training followed by validation \n",
    "        \n",
    "        model.train() if is_training else model.eval()\n",
    "        \n",
    "        running_loss = 0\n",
    "        for features, targets in (dataloader_train if is_training else dataloader_valid):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(is_training):\n",
    "                outputs = model(features)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                if is_training:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()               \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if is_training:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if is_training:\n",
    "            train_loss = running_loss / len(dataloader_train.dataset)\n",
    "        else:\n",
    "            valid_loss = running_loss / len(dataloader_valid.dataset)\n",
    "    \n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 0 ----------------\n",
      "New Best Validiation Loss!!! 0.7178543238019993\n",
      "Training Loss: 0.7310521936900505\n",
      "Validation Loss: 0.7178543238019993\n",
      "--------------- Epoch 1 ----------------\n",
      "New Best Validiation Loss!!! 0.11523285561869924\n",
      "Training Loss: 0.3913191823458899\n",
      "Validation Loss: 0.11523285561869924\n",
      "--------------- Epoch 2 ----------------\n",
      "Training Loss: 0.17817531035959744\n",
      "Validation Loss: 0.250456654742675\n",
      "--------------- Epoch 3 ----------------\n",
      "Training Loss: 0.23853697597961349\n",
      "Validation Loss: 0.22833728613120075\n",
      "--------------- Epoch 4 ----------------\n",
      "Training Loss: 0.20820969153931795\n",
      "Validation Loss: 0.1870486117016761\n",
      "--------------- Epoch 5 ----------------\n",
      "Training Loss: 0.16448670123396747\n",
      "Validation Loss: 0.14556989838783918\n",
      "--------------- Epoch 6 ----------------\n",
      "Training Loss: 0.1359182247466396\n",
      "Validation Loss: 0.14176831089265057\n",
      "--------------- Epoch 7 ----------------\n",
      "Training Loss: 0.13189525021429163\n",
      "Validation Loss: 0.13800831978660894\n",
      "--------------- Epoch 8 ----------------\n",
      "Training Loss: 0.12810989298236533\n",
      "Validation Loss: 0.1342704893989269\n",
      "--------------- Epoch 9 ----------------\n",
      "Training Loss: 0.12531846541247055\n",
      "Validation Loss: 0.13390074153955392\n",
      "--------------- Epoch 10 ----------------\n",
      "Training Loss: 0.1249168886017682\n",
      "Validation Loss: 0.1335317278400893\n",
      "--------------- Epoch 11 ----------------\n",
      "Training Loss: 0.12452575744433023\n",
      "Validation Loss: 0.1331572167239973\n",
      "--------------- Epoch 12 ----------------\n",
      "Training Loss: 0.12425575167522905\n",
      "Validation Loss: 0.13311891796351175\n",
      "--------------- Epoch 13 ----------------\n",
      "Training Loss: 0.12421476431700466\n",
      "Validation Loss: 0.13308006431733735\n",
      "--------------- Epoch 14 ----------------\n",
      "Training Loss: 0.12417355449485304\n",
      "Validation Loss: 0.1330404646542991\n",
      "\n",
      "\n",
      "FINISHED TRAINING\n",
      "Best validation lost: 0.11523285561869924\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = 9999999\n",
    "best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"--------------- Epoch {epoch} ----------------\")\n",
    "    train_loss, val_loss = train(model = model,\n",
    "                                 dataloader_train = dataloader_train,\n",
    "                                 dataloader_valid = dataloader_valid,\n",
    "                                 loss_fn = loss_fn,\n",
    "                                 optimizer = optimizer,\n",
    "                                 scheduler = scheduler,\n",
    "                                 device = device)\n",
    "    \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "        print(\"New Best Validiation Loss!!!\", val_loss)\n",
    "    \n",
    "    print(\"Training Loss:\", train_loss)\n",
    "    print(\"Validation Loss:\", val_loss)\n",
    "print(\"\\n\\nFINISHED TRAINING\")\n",
    "print(f\"Best validation lost: {best_valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.load_state_dict(best_model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Spearman's rank correlation, ROC curves, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-mem",
   "language": "python",
   "name": "video-mem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
