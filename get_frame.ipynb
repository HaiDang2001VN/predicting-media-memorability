{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'./training_set/Videos/'\n",
    "frame_path = r'./training_set/Frames/'\n",
    "n_frame_path = r'./training_set/N-Frames/'\n",
    "feature_path = r'./training_set/Features/AlexNetFC7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_log = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(feature_path):\n",
    "    video_name = filename[0:5] #because videos in Features use format xxxxx-xxx.csv\n",
    "    frame_num = filename[6:9]\n",
    "    frame_filename = frame_path + video_name + '-' + frame_num + '.png'\n",
    "    if not os.path.exists(frame_filename):\n",
    "        cap = cv2.VideoCapture(video_path + str(int(video_name)) + '.mp4')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_num) - 1)\n",
    "        res, frame = cap.read()\n",
    "        if res == 0:\n",
    "            error_log.append((video_name, frame_num))\n",
    "        else:\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually iterate through error_log video frames until we get the frame\n",
    "\n",
    "for video_name, frame_number in error_log:\n",
    "    cap = cv2.VideoCapture(video_path + str(int(video_name)) + \".mp4\")\n",
    "    i = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            print(f\"Did not find frame {frame_number} of {video_name}\")\n",
    "            break\n",
    "        if i == int(frame_number):\n",
    "            cv2.imwrite(frame_path + video_name + '-' + frame_number + '.png', frame)\n",
    "            break\n",
    "        i += 1\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract n frame per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(n_frame_path):\n",
    "    os.mkdir(n_frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_frame(video):\n",
    "    total = 0\n",
    "\n",
    "    while True:\n",
    "        (grabbed, frame) = video.read()\n",
    "        \n",
    "        if not grabbed:\n",
    "            break\n",
    "        \n",
    "        total += 1\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_indexes(total_frame, n):\n",
    "    return [int(i) for i in np.around(np.linspace(0, total_frame, n))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 14, 29, 43, 57, 71, 86, 100]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frame_indexes(100, 8) #sanity check to confirm approximately evenly spaced frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71042eba4504a419fb736069667fbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=590.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 8 #number of frame we want to extract\n",
    "error_log_2 = list()\n",
    "\n",
    "for filename in tqdm(os.listdir(video_path)):\n",
    "    video_name = filename.split(\".\")[0].zfill(5)\n",
    "    cap = cv2.VideoCapture(video_path + filename)\n",
    "\n",
    "    total_frame = get_total_frame(cap) #total number of frame of this video\n",
    "    frame_indexes = get_frame_indexes(total_frame, n) #the index of the frame of interest\n",
    "    \n",
    "    video_n_frames_folder = f\"{n_frame_path}{video_name}\"\n",
    "    if not os.path.exists(video_n_frames_folder):\n",
    "        os.mkdir(video_n_frames_folder)\n",
    "\n",
    "    for frame_index in frame_indexes:\n",
    "        frame_filename = f\"{video_n_frames_folder}/{str(frame_index).zfill(3)}.png\"\n",
    "\n",
    "        if os.path.exists(frame_filename): #Already extracted frame, continue to next\n",
    "            continue\n",
    "            \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index - 1)\n",
    "        res, frame = cap.read()\n",
    "        if res == 0:\n",
    "            error_log_2.append((video_path+filename, frame_index))\n",
    "        else:\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./training_set/Videos/2568.mp4', 185), ('./training_set/Videos/2934.mp4', 160), ('./training_set/Videos/1965.mp4', 187), ('./training_set/Videos/5657.mp4', 130), ('./training_set/Videos/2675.mp4', 144), ('./training_set/Videos/165.mp4', 187), ('./training_set/Videos/4949.mp4', 155), ('./training_set/Videos/4461.mp4', 166), ('./training_set/Videos/2152.mp4', 173), ('./training_set/Videos/2476.mp4', 188)]\n"
     ]
    }
   ],
   "source": [
    "print(error_log_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_file, frame_index in error_log_2:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    video_name = video_file.split(\"/\")[-1].split(\".\")[0].zfill(5)\n",
    "    \n",
    "    extracted = False\n",
    "    while not extracted:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        extracted, frame = cap.read()\n",
    "        frame_index -= 1 # try the previous frame\n",
    "    \n",
    "    cv2.imwrite(f\"{n_frame_path}{video_name}/{str(frame_index).zfill(3)}.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
